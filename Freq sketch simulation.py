# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:percent
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.16.4
#   kernelspec:
#     display_name: Python 3 (ipykernel)
#     language: python
#     name: python3
# ---

# %%
import numpy as np
import math
import pandas as pd
from multiprocessing.pool import ThreadPool
from tqdm.notebook import tqdm, trange
import time
import heapq

from typing import List, Any, Tuple

# %%
### Load data
_df = pd.read_csv('data/AOL-user-ct-collection/user-ct-test-collection-01.txt', sep='\t')
_df['Query'] = _df['Query'].fillna("")
df = _df.sample(100000)
df.head()

# %%
unique_counts = df['Query'].value_counts()
unique_counts

# %%
hash_rng = np.random.default_rng()
query_items = df['Query'].unique()
def generate_hash_function():
    a, b = np.random.randint(1, 1000000007, size=2)
    h = lambda x: ((a * hash(x) + b) % 1000000007)
    hashes = {}
    for item in query_items:
        hashes[item] = h(item)
    return hashes


# %%
# Used as an intermediate DS for PPSWOR
# Generated by Claude
class CountSketchTopK:
    def __init__(self, width: int, depth: int, k: int):
        self.width = width
        self.depth = depth
        self.sketch = np.zeros((self.depth, self.width), dtype=float)
        self.hash_functions = [self._generate_hash_function() for _ in range(self.depth)]
        self.sign_functions = [self._generate_sign_function() for _ in range(self.depth)]
        self.heap = []
        self.k = k

    def _generate_hash_function(self):
        hashes = generate_hash_function()
        for item, h in hashes.items():
            hashes[item] = h % self.width
        return hashes

    def _generate_sign_function(self):
        hashes = generate_hash_function()
        for item, h in hashes.items():
            hashes[item] = 1 if h % 2 == 0 else -1
        return hashes

    def update(self, item: Any, count: int = 1) -> None:
        # Update count
        for i in range(self.depth):
            j = self.hash_functions[i][item]
            s = self.sign_functions[i][item]
            self.sketch[i, j] += s * count

        # Insert item into heap
        if len(self.heap) < self.k:
            heapq.heappush(self.heap, (self.estimate(item), item))
            return

        # See if this element is now in top-k
        heap_index = -1
        for i, top_item in enumerate(self.heap):
            if top_item[1] == item:
                heap_index = i

        if heap_index != -1:
            self.heap[heap_index] = (self.estimate(item), item)
            heapq.heapify(self.heap)
        else:
            # Since self.heap is a min-heap, this should keep the top-k items
            heapq.heappushpop(self.heap, (self.estimate(item), item))

    def estimate(self, item: Any) -> float:
        estimates = np.empty(self.depth)
        for i in range(self.depth):
            j = self.hash_functions[i][item]
            s = self.sign_functions[i][item]
            estimates[i] = s * self.sketch[i, j]
        estimates.sort()
        median = (estimates[int(len(estimates)/2)] + estimates[int((len(estimates) - 1)/2)]) / 2
        return median

    def heavy_hitters(self) -> List[Any]:
        return [heap_item[1] for heap_item in self.heap]

    def space_size(self) -> int:
        return self.width * self.depth + self.k


# %%
class PPSWOR:
    def __init__(self, k: int):
        self.k = k
        self.cs = CountSketchTopK(int(10/0.05**2), 7, k+1)
        self.seed = self._generate_seed()

    def _generate_seed(self):
        hashes = generate_hash_function()
        for item, h in hashes.items():
            rng = np.random.default_rng(h)
            hashes[item] = rng.exponential(1)
        return hashes

    def update(self, item: Any, count: int = 1) -> None:
        w_x = count / np.sqrt(self.seed[item])
        self.cs.update(item, w_x)

    def sample(self) -> Tuple[List[Any], List[float]]:
        tau = self.cs.heap[0][0]
        sample = np.array([self.cs.estimate(item) * np.sqrt(self.seed[item]) for item in self.cs.heavy_hitters()])
        sample_probs = 1 - np.exp(-((sample/tau)**2))
        return sample[1:], sample_probs[1:]

    def space_size(self) -> int:
        return self.cs.space_size()


# %%
class FrequencyOracle:
    """
    We emulate a frequency oracle by finding the true count of an item c, and return a
    uniform estimate between [(1-ep)*c, (1+ep)*c]
    """
    def __init__(self, ep: float, dataset):
        self.estimates = self._generate_estimates(ep, dataset)

    def _generate_estimates(self, ep: float, df):
        estimates = {}
        rng = np.random.default_rng()

        for item, count in df['Query'].value_counts().items():
            estimates[item] = rng.uniform((1-ep) * count, (1+ep) * count)
        return estimates
    
    def estimate(self, item: Any) -> float:
        return self.estimates[item]


# %%
class SampleWithAdvice:
    def __init__(self, kh, ku, kp, oracle: FrequencyOracle):
        self.oracle = oracle
        self.kh = kh
        self.ku = ku
        self.kp = kp
        self.h_heap = []
        self.p_heap = []
        self.u_heap = []
        self.seed = self._generate_seed()

    def _generate_seed(self):
        hashes = generate_hash_function()
        for item, h in hashes.items():
            rng = np.random.default_rng(h)
            hashes[item] = rng.exponential()
        return hashes

    def _try_insert(self, item, heap, k):
        if len(heap) < k:
            heapq.heappush(heap, item)
            return None
        return heapq.heappushpop(heap, item)
        
    def update(self, item: Any, count: int = 1):
        # Check if item is already in heap; if so, just update count
        # Shouldn't need to reheapify, since heap is not ordered by count
        for heap in [self.h_heap, self.p_heap, self.u_heap]:
            for i, h_item in enumerate(heap):
                if h_item[1] == item:
                    heap[i] = (h_item[0], h_item[1], h_item[2] + count)
                    return

        # Insertion order: h_heap -> p_heap -> u_heap
        c_estimate = self.oracle.estimate(item)
        overflow = self._try_insert((c_estimate, item, count), self.h_heap, self.kh)
        if overflow is None: return
        else: item, count = overflow[1], overflow[2]

        weight = self.oracle.estimate(item)**2 / self.seed[item]
        overflow = self._try_insert((weight, item, count), self.p_heap, self.kp + 1)
        if overflow is None: return
        else: item, count = overflow[1], overflow[2]

        weight = -self.seed[item]
        self._try_insert((weight, item, count), self.u_heap, self.ku + 1)

    def sample(self):
        sample_h = np.array([item[2] for item in self.h_heap])
        sample_h_probs = np.ones(self.kh)

        tau = heapq.heappop(self.p_heap)[0]
        sample_p = np.array([item[2] for item in self.p_heap])
        sample_p_probs = np.array([1 - np.exp(-self.oracle.estimate(item[1])**2 / tau) for item in self.p_heap])

        tau = -heapq.heappop(self.u_heap)[0]
        sample_u = np.array([item[2] for item in self.u_heap])
        sample_u_probs = np.full(self.ku, 1 - np.exp(-tau))

        return np.concatenate((sample_h, sample_p, sample_u)), np.concatenate((sample_h_probs, sample_p_probs, sample_u_probs))

    def space_size(self):
        return self.kh + self.kp + self.ku


# %%
### Experiments
actual_value = np.linalg.norm(unique_counts)
print("Actual L2 Norm:", actual_value)

def estimate_norm(weights, sample_probs):
    return np.sqrt(np.sum(weights**2 / sample_probs))


# %%
from prettytable import PrettyTable

cs = CountSketchTopK(int(10/0.05**2), 15, 100)
sketch = PPSWOR(100)
for _, query in df['Query'].items():
    sketch.update(query)
    cs.update(query)

# %%
ppswor_sample, ppswor_sample_probs = sketch.sample()
ppswor_sample_items = sketch.cs.heavy_hitters()
print(estimate_norm(ppswor_sample, ppswor_sample_probs))

t = PrettyTable(["query", "count", "est_count", "sample_prob"])
for i in range(100):
    item = ppswor_sample_items[i]
    t.add_row([item, unique_counts[item], ppswor_sample[i], ppswor_sample_probs[i]])

# t = PrettyTable(["query", "count", "est_count", "seed", "sample_prob"])
# for item, count in unique_counts.iloc[:100].items():
#     sample = sketch.cs.estimate(item) * np.sqrt(sketch.seed[item])
#     seed = sketch.seed[item]
#     tau = sketch.cs.heap[0][0]
#     sample_prob = 1 - np.exp(-((sample/tau)**2))
#     t.add_row([item, count, sample, seed, sample_prob])

# t = PrettyTable(["query", "count"])
# for item in cs.heavy_hitters():
#     t.add_row([item, cs.estimate(item)])

# for i in range(sketch.cs.depth):
#     j = sketch.cs.hash_functions[i]['-']
#     s = sketch.cs.sign_functions[i]['-']
#     print(s * sketch.cs.sketch[i, j])

print(t.get_string(sortby="count", reversesort=True))


# %%
def get_ppswor_estimate(pbar):
    sketch = PPSWOR(100)
    for _, query in df['Query'].items():
        sketch.update(query)
        pbar.update()
    ppswor_sample, ppswor_sample_probs = sketch.sample()
    return estimate_norm(ppswor_sample, ppswor_sample_probs)

n_sims = 10
pbar = tqdm(total=len(df['Query']), position=1)
estimates = np.empty(n_sims)
for i in trange(n_sims, position=0):
    pbar.reset()
    estimates[i] = get_ppswor_estimate(pbar)
    pbar.refresh()
pbar.close()
print(estimates)
print("PPSWOR Mean:", np.mean(estimates))
print("PPSWOR MSE:", np.mean((estimates - actual_value)**2))


# %%
def get_swa_estimate(pbar):
    oracle = FrequencyOracle(0.1, df)
    swa = SampleWithAdvice(10, 60, 30, oracle)
    for _, query in df['Query'].items():
        swa.update(query)
        pbar.update()
    swa_sample, swa_sample_probs = swa.sample()
    return estimate_norm(swa_sample, swa_sample_probs)

n_sims = 10
pbar = tqdm(total=len(df['Query']), position=1)
estimates = np.empty(n_sims)
for i in trange(n_sims, position=0):
    pbar.reset()
    estimates[i] = get_swa_estimate(pbar)
    pbar.refresh()
pbar.close()
print(estimates)
print("SWA Mean:", np.mean(estimates))
print("SWA MSE:", np.mean((estimates - actual_value)**2))
